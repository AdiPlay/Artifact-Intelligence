{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Data Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1-Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./card_transdata.csv\n",
      "./projekt.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, mean_squared_error, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "from torch.nn import ReLU, Linear, BatchNorm1d, Dropout, Sequential, Module, BCEWithLogitsLoss\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('./'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2- Improting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_from_home</th>\n",
       "      <th>distance_from_last_transaction</th>\n",
       "      <th>ratio_to_median_purchase_price</th>\n",
       "      <th>repeat_retailer</th>\n",
       "      <th>used_chip</th>\n",
       "      <th>used_pin_number</th>\n",
       "      <th>online_order</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57.877857</td>\n",
       "      <td>0.311140</td>\n",
       "      <td>1.945940</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.829943</td>\n",
       "      <td>0.175592</td>\n",
       "      <td>1.294219</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.091079</td>\n",
       "      <td>0.805153</td>\n",
       "      <td>0.427715</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.247564</td>\n",
       "      <td>5.600044</td>\n",
       "      <td>0.362663</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44.190936</td>\n",
       "      <td>0.566486</td>\n",
       "      <td>2.222767</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.586408</td>\n",
       "      <td>13.261073</td>\n",
       "      <td>0.064768</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.724019</td>\n",
       "      <td>0.956838</td>\n",
       "      <td>0.278465</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.848247</td>\n",
       "      <td>0.320735</td>\n",
       "      <td>1.273050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.876632</td>\n",
       "      <td>2.503609</td>\n",
       "      <td>1.516999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.839047</td>\n",
       "      <td>2.970512</td>\n",
       "      <td>2.361683</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   distance_from_home  distance_from_last_transaction   \n",
       "0           57.877857                        0.311140  \\\n",
       "1           10.829943                        0.175592   \n",
       "2            5.091079                        0.805153   \n",
       "3            2.247564                        5.600044   \n",
       "4           44.190936                        0.566486   \n",
       "5            5.586408                       13.261073   \n",
       "6            3.724019                        0.956838   \n",
       "7            4.848247                        0.320735   \n",
       "8            0.876632                        2.503609   \n",
       "9            8.839047                        2.970512   \n",
       "\n",
       "   ratio_to_median_purchase_price  repeat_retailer  used_chip   \n",
       "0                        1.945940              1.0        1.0  \\\n",
       "1                        1.294219              1.0        0.0   \n",
       "2                        0.427715              1.0        0.0   \n",
       "3                        0.362663              1.0        1.0   \n",
       "4                        2.222767              1.0        1.0   \n",
       "5                        0.064768              1.0        0.0   \n",
       "6                        0.278465              1.0        0.0   \n",
       "7                        1.273050              1.0        0.0   \n",
       "8                        1.516999              0.0        0.0   \n",
       "9                        2.361683              1.0        0.0   \n",
       "\n",
       "   used_pin_number  online_order  fraud  \n",
       "0              0.0           0.0    0.0  \n",
       "1              0.0           0.0    0.0  \n",
       "2              0.0           1.0    0.0  \n",
       "3              0.0           1.0    0.0  \n",
       "4              0.0           1.0    0.0  \n",
       "5              0.0           0.0    0.0  \n",
       "6              0.0           1.0    0.0  \n",
       "7              1.0           0.0    0.0  \n",
       "8              0.0           0.0    0.0  \n",
       "9              0.0           1.0    0.0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('./card_transdata.csv')\n",
    "dataset = dataset.dropna()\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 8 columns):\n",
      " #   Column                          Non-Null Count    Dtype  \n",
      "---  ------                          --------------    -----  \n",
      " 0   distance_from_home              1000000 non-null  float64\n",
      " 1   distance_from_last_transaction  1000000 non-null  float64\n",
      " 2   ratio_to_median_purchase_price  1000000 non-null  float64\n",
      " 3   repeat_retailer                 1000000 non-null  float64\n",
      " 4   used_chip                       1000000 non-null  float64\n",
      " 5   used_pin_number                 1000000 non-null  float64\n",
      " 6   online_order                    1000000 non-null  float64\n",
      " 7   fraud                           1000000 non-null  float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 61.0 MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='fraud', ylabel='count'>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_context('paper', font_scale=1)\n",
    "sns.set_style('ticks')\n",
    "sns.countplot(x='fraud', data=dataset, palette='deep')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose all columns as our matrix of features except the last one, which is 'y' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X:  (1000000, 7)\n",
      "Shape of y:  (1000000,)\n"
     ]
    }
   ],
   "source": [
    "dataset.fraud.value_counts()\n",
    "print('Shape of X: ', np.shape(X))\n",
    "print('Shape of y: ', np.shape(y))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3- Oversampling and Train, Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X:  (1825194, 7)\n",
      "Shape of y:  (1825194,)\n",
      "Shape of X_train:  (1277635, 7)\n",
      "Shape of y_train:  (1277635,)\n",
      "Shape of X_test:  (547559, 7)\n",
      "Shape of y_test:  (547559,)\n"
     ]
    }
   ],
   "source": [
    "X, y = SMOTE().fit_resample(X, y)\n",
    "print('Shape of X: ', np.shape(X))\n",
    "print('Shape of y: ', np.shape(y))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "print('Shape of X_train: ', np.shape(X_train))\n",
    "print('Shape of y_train: ', np.shape(y_train))\n",
    "print('Shape of X_test: ', np.shape(X_test))\n",
    "print('Shape of y_test: ', np.shape(y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_acc_loss(train, epochs, plttype):\n",
    "    epochstoplot = range(1, epochs + 1)\n",
    "    plt.plot(epochstoplot, train, label='Training' + plttype)\n",
    "    plt.title('Training ' + plttype)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(plttype)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1- Deep Learning\n",
    "Defining Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.00146\n",
    "WORKERS = 2\n",
    "WD = 1e-6\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "class TestData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "train_data = TrainData(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n",
    "test_data = TestData(torch.FloatTensor(X_test), torch.FloatTensor(y_test))\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=WORKERS)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=True, num_workers=WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2- Neural Network with 3 different layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "\n",
    "        #Number of input features is 7.\n",
    "        self.layer_1 = Linear(7, 64)\n",
    "        self.layer_2 = Linear(64, 64)\n",
    "        self.layer_out = Linear(64, 1)\n",
    "\n",
    "        self.relu = ReLU()\n",
    "        self.dropout = Dropout(p=0.1)\n",
    "        self.batchnorm1 = BatchNorm1d(64)\n",
    "        self.batchnorm2 = BatchNorm1d(64)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "    \n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5><b>2.3- Training<b><h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 10864, 8644) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\kokos\\miniconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1131\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1132\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m   1133\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n",
      "File \u001b[1;32mc:\\Users\\kokos\\miniconda3\\lib\\multiprocessing\\queues.py:114\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll(timeout):\n\u001b[1;32m--> 114\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m epoch_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     15\u001b[0m epoch_acc \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m---> 16\u001b[0m \u001b[39mfor\u001b[39;00m X_batch, y_batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m     17\u001b[0m     X_batch, y_batch \u001b[39m=\u001b[39m X_batch\u001b[39m.\u001b[39mto(device), y_batch\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     19\u001b[0m     y_pred \u001b[39m=\u001b[39m model(X_batch)\n",
      "File \u001b[1;32mc:\\Users\\kokos\\miniconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\kokos\\miniconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1325\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[0;32m   1327\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m-> 1328\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[0;32m   1329\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1330\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[0;32m   1331\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kokos\\miniconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1294\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1290\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1291\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1292\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1293\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m-> 1294\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[0;32m   1295\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[0;32m   1296\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\kokos\\miniconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1145\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1143\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(failed_workers) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1144\u001b[0m     pids_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mstr\u001b[39m(w\u001b[39m.\u001b[39mpid) \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m failed_workers)\n\u001b[1;32m-> 1145\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mDataLoader worker (pid(s) \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) exited unexpectedly\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(pids_str)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e, queue\u001b[39m.\u001b[39mEmpty):\n\u001b[0;32m   1147\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mFalse\u001b[39;00m, \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 10864, 8644) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "accuracy_stats = []\n",
    "loss_stats = []\n",
    "\n",
    "model = NeuralNet()\n",
    "model.to(device)\n",
    "loss = BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, weight_decay=WD)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for i in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        y_pred = model(X_batch)\n",
    "        l = loss(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "\n",
    "        epoch_loss += l.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "\n",
    "    print(f'Epoch {i:02d} / {EPOCHS:02d}: | Loss: {epoch_loss/len(train_loader):.4f} | Acc: {epoch_acc/len(train_loader):.3f}')\n",
    "    loss_stats.append(epoch_loss / len(train_loader))\n",
    "    accuracy_stats.append(epoch_acc / len(train_loader))\n",
    "\n",
    "\n",
    "print('\\nTraining is completed!')\n",
    "print('_____________________________')\n",
    "print(f'Total Training Time: {(time.time() - start_time)/60:.2f} min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_acc_loss(loss_stats, EPOCHS, 'Loss')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
